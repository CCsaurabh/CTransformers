# [Performance Evaluation Llama-7B](https://github.com/HSaurabh0919/CTransformers/tree/main/LangChain)
1.  Llama-7b model performanc is good with theoretical questions and iamge generations.
2.  Able to solve fundamental csv problems
3.  Stucks in more complex problem requiring more logical reasoning
4.  Can provide good results with user database.
5.  Performance is good when producing multiple results from same prompt, novelty is maintained.


# [Performance Evaluation of Open Source Chat Models](https://github.com/HSaurabh0919/CTransformers/tree/main/LangChain)
1. Performance of [Llama-2-7b-chat-hf](Llama/Llama_chat_hf_1.ipynb) seems reasonably good on open type questions.
2. Performance of [RedPajama-3b](https://github.com/HSaurabh0919/CTransformers/blob/main/Llama/Performance_Evaluation_RedPajama_Chat_3B.ipynb) models are as below.
    * Able to answer Open source type question
    * For Context Aware Questions, sometime answers are irrelevant, sometime not able to reproduce results
    * Very poor performance on multiple answer questions.
