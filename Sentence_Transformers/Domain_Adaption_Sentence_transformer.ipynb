{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMswb+dZ5d3nAuFuAI2wGoT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2tBaUFD7iFC"
      },
      "outputs": [],
      "source": [
        "!pip install gpl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/fiqa.zip\n",
        "!unzip fiqa.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVAV_LUc-8yP",
        "outputId": "c5127fc5-11b9-49e8-e815-8683686a7dc8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-04 11:22:50--  https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/fiqa.zip\n",
            "Resolving public.ukp.informatik.tu-darmstadt.de (public.ukp.informatik.tu-darmstadt.de)... 130.83.167.186\n",
            "Connecting to public.ukp.informatik.tu-darmstadt.de (public.ukp.informatik.tu-darmstadt.de)|130.83.167.186|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17948027 (17M) [application/zip]\n",
            "Saving to: ‘fiqa.zip’\n",
            "\n",
            "fiqa.zip            100%[===================>]  17.12M  7.50MB/s    in 2.3s    \n",
            "\n",
            "2023-04-04 11:22:54 (7.50 MB/s) - ‘fiqa.zip’ saved [17948027/17948027]\n",
            "\n",
            "Archive:  fiqa.zip\n",
            "   creating: fiqa/\n",
            "   creating: fiqa/qrels/\n",
            "  inflating: fiqa/qrels/train.tsv    \n",
            "  inflating: fiqa/qrels/test.tsv     \n",
            "  inflating: fiqa/qrels/dev.tsv      \n",
            "  inflating: fiqa/corpus.jsonl       \n",
            "  inflating: fiqa/queries.jsonl      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 2 fiqa/corpus.jsonl  # One can check this data format. Actually GPL only need this `corpus.jsonl` as data input for training."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF9_-6ye_Nqj",
        "outputId": "7eeb9f86-30af-4853-831a-8f55f91cae63"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"_id\": \"3\", \"title\": \"\", \"text\": \"I'm not saying I don't like the idea of on-the-job training too, but you can't expect the company to do that. Training workers is not their job - they're building software. Perhaps educational systems in the U.S. (or their students) should worry a little about getting marketable skills in exchange for their massive investment in education, rather than getting out with thousands in student debt and then complaining that they aren't qualified to do anything.\", \"metadata\": {}}\n",
            "{\"_id\": \"31\", \"title\": \"\", \"text\": \"So nothing preventing false ratings besides additional scrutiny from the market/investors, but there are some newer controls in place to prevent institutions from using them. Under the DFA banks can no longer solely rely on credit ratings as due diligence to buy a financial instrument, so that's a plus. The intent being that if financial institutions do their own leg work then *maybe* they'll figure out that a certain CDO is garbage or not.  Edit: lead in\", \"metadata\": {}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text"
      ],
      "metadata": {
        "id": "WeI6UYP8_qDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gpl\n",
        "\n",
        "dataset = 'fiqa'\n",
        "gpl.train(\n",
        "    path_to_generated_data=f\"generated/{dataset}\",\n",
        "    base_ckpt=\"distilbert-base-uncased\",  \n",
        "    # base_ckpt='GPL/msmarco-distilbert-margin-mse',  \n",
        "    # The starting checkpoint of the experiments in the paper\n",
        "    gpl_score_function=\"dot\",\n",
        "    # Note that GPL uses MarginMSE loss, which works with dot-product\n",
        "    batch_size_gpl=32,\n",
        "    gpl_steps=140000,\n",
        "    new_size=-1,\n",
        "    # Resize the corpus to `new_size` (|corpus|) if needed. When set to None (by default), the |corpus| will be the full size. When set to -1, the |corpus| will be set automatically: If QPP * |corpus| <= 250K, |corpus| will be the full size; else QPP will be set 3 and |corpus| will be set to 250K / 3\n",
        "    queries_per_passage=-1,\n",
        "    # Number of Queries Per Passage (QPP) in the query generation step. When set to -1 (by default), the QPP will be chosen automatically: If QPP * |corpus| <= 250K, then QPP will be set to 250K / |corpus|; else QPP will be set 3 and |corpus| will be set to 250K / 3\n",
        "    output_dir=f\"output/{dataset}\",\n",
        "    evaluation_data=f\"./{dataset}\",\n",
        "    evaluation_output=f\"evaluation/{dataset}\",\n",
        "    generator=\"BeIR/query-gen-msmarco-t5-base-v1\",\n",
        "    retrievers=[\"msmarco-distilbert-base-v3\", \"msmarco-MiniLM-L-6-v3\"],\n",
        "    retriever_score_functions=[\"cos_sim\", \"cos_sim\"],\n",
        "    # Note that these two retriever model work with cosine-similarity\n",
        "    cross_encoder=\"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
        "    qgen_prefix=\"qgen\",\n",
        "    # This prefix will appear as part of the (folder/file) names for query-generation results: For example, we will have \"qgen-qrels/\" and \"qgen-queries.jsonl\" by default.\n",
        "    do_evaluation=True,\n",
        "    # use_amp=True   # One can use this flag for enabling the efficient float16 precision\n",
        ")"
      ],
      "metadata": {
        "id": "NxioD5yz_coI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REFERENCE : https://github.com/UKPLab/gpl"
      ],
      "metadata": {
        "id": "zd9fdZusBLVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g4VBkcgx_j4b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}