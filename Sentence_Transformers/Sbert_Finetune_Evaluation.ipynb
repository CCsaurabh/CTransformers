{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbBOOCL3e2rLRRFUYo9dUa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tT1W9q_durKU"
      },
      "outputs": [],
      "source": [
        "!pip install SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the SBERT model\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "# Load the training data into a pandas dataframe\n",
        "df = pd.read_csv('training_data.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Create a list of InputExample objects\n",
        "examples = []\n",
        "for i, row in df.iterrows():\n",
        "    examples.append(InputExample(texts=[row['text_a'], row['text_b']], label=row['score']))\n",
        "\n",
        "\n",
        "test_examples = []\n",
        "for i, row in test_df.iterrows():\n",
        "    test_examples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=row['label']))\n",
        "\n",
        "# Define the training data generator\n",
        "def data_generator(examples, batch_size=16):\n",
        "    for i in range(0, len(examples), batch_size):\n",
        "        batch = examples[i:i+batch_size]\n",
        "        texts = [example.texts for example in batch]\n",
        "        labels = [example.label for example in batch]\n",
        "        yield texts, labels\n",
        "\n",
        "# Define the training loss function\n",
        "train_loss = losses.CosineSimilarityLoss(model)\n",
        "\n",
        "# Fine-tune the model\n",
        "model.fit(\n",
        "    data_generator(examples),\n",
        "    epochs=5,\n",
        "    steps_per_epoch=int(np.ceil(len(examples) / 16)),\n",
        "    warmup_steps=100,\n",
        "    loss=train_loss,\n",
        ")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save('finetuned_model')\n"
      ],
      "metadata": {
        "id": "rTx6YzLNur57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the fine-tuned model\n",
        "model = SentenceTransformer('finetuned_model')\n",
        "\n",
        "# Encode the test examples\n",
        "test_embeddings = model.encode([(example.texts[0], example.texts[1]) for example in test_examples])\n",
        "\n",
        "# Compute the cosine similarity scores between the test embeddings\n",
        "similarity_scores = []\n",
        "for i in range(len(test_embeddings)):\n",
        "    score = cosine_similarity([test_embeddings[i][0]], [test_embeddings[i][1]])[0][0]\n",
        "    similarity_scores.append(score)\n",
        "\n",
        "# Compute the classification report\n",
        "y_true = [example.label for example in test_examples]\n",
        "y_pred = [1 if score >= 0.5 else 0 for score in similarity_scores]\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "_ZVcXv9-wliE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}